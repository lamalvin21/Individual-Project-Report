% Future tense
\chapter{Introduction}
This first chapter will introduce the rationale and scope for the project.

\section{Rationale}
There are many information sources today that are still not computationally represented or fully explored on the World Wide Web (WWW). In a book \cite{bizer2011linked}, the authors (including creator of the WWW: Tim Berners-Lee) discuss vast amounts of structured data published on the WWW, but show there is ample opportunity for further exploration of other topics. Therefore, there is demand for a means of representing information, potentially through the use of knowledge graphs, in order to make vast amounts of web data available for computational and human use. Finding an automated way to generate knowledge graphs from structured data or text found on the WWW is vital to addressing this demand. Current solutions to generating knowledge graphs include: SPARQL-Generate \cite{sparqlgenerate}, RML \cite{rml} and ChatGPT \cite{chatgptwebsite}. However, these tools are limited by their scope and complexity to reach the solution, so selecting SPARQL Anything \cite{sparqlanythinggithub} for implementation is most favourable. 

Generating knowledge graphs directly from datasets is not trivial as the process is complex and requires an understanding of knowledge engineering. Knowledge engineering, itself, requires experience and research in areas such as: what ontologies to create or use, what vocabularies to use and what classes to use. So generating knowledge graphs from a dataset is not instantaneous and requires extensive research. In the case of smaller knowledge graphs, it is possible to manually create knowledge graphs without the use of a tool. Nonetheless, physically building the knowledge graph triple by triple would be time-consuming and is prone to human error, especially for larger knowledge graphs and datasets. This approach is also not sustainable. 

\section{Aims}
The aim of this project is to use SPARQL Anything and a given organ-oriented dataset to create a knowledge graph. Integration of various sources of data into a single, encapsulated knowledge graph can enable the sharing and understandability of this information by both humans and machines. Knowledge graphs may provide economic advantages by reducing the time and effort to analyse vast amounts of data. Consumers may use the knowledge graphs for their own needs or follow the process detailed in the report to create their own knowledge graphs.

To the extent of our research, creating knowledge graphs for this particular subject (organs) had not yet been fully explored in this level of detail. For instance, knowledge graphs were previously developed for music recommendation systems \cite{oramas2016sound} by other researchers. So knowledge graph generation techniques had been done previously, but methodology employed is of a different context to our problem. Existing organ knowledge graphs on Wikidata \cite{organwikidata}, MusicBrainz \cite{organmusicbrainz} and DBpedia \cite{organdbpedia} are sufficient for basic familiarity, but do not go into the same level of detail as the knowledge graph created in this project. This project also aims to address this particular knowledge representation gap. 

\section{Scope}
The project is part of the Polifonia project, which seeks to create an ecosystem of computational tools and methodologies to spread knowledge about musical history on the internet \cite{polifoniaproject}. Therefore, this report assists the Polifonia project in achieving its objectives and facilitates its progression. This designated project involves a dataset centred around organs so the report includes a breakdown of the various organ components as well as background information regarding technical knowledge. 

This project will detail the process of knowledge graph generation using an organ-orientated dataset and provided ontology, both of which are contextualised to understand the dataset fully and to refine the existing ontology. In order to commence, knowledge of the semantic web and its capabilities are required so as to understand the scope of the project. Researching and being able to interpret RDF, ontologies and knowledge graphs is also required to reach the solution as well as interpret it. 

The following chapters provide a comprehensive view of the design and implementation process for generating knowledge graphs. The design chapter complements the implementation phase by using visual tools and careful planning through software development techniques. Subsequently, the implementation chapter meticulously explains the steps required to reach the final solution. A thorough evaluation of the produced knowledge graph is performed with both qualitative and quantitative forms of assessment being carried out. The legal, social, ethical and professional issues surrounding this project are also reviewed to adhere to the Code of Conduct \& Code of Good Practice issued by the British Computer Society \cite{bcs} as well as the FAIR Principles \cite{fairprinciples}. This is also intended to assist in identifying any potential issues that may arise for the duration of the project.

Finally, the conclusion will summarise work completed during the course of this project and include a discussion on future work and limitations. 
