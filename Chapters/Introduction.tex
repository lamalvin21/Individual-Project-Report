\chapter{Introduction}
There are many information sources today there are still not computationally represented or explored fully on the web. Therefore, there is demand for a means to represent this information in the form of knowledge graphs, so the vast amounts of data on the web can be available to use by anyone. Finding an automated way to generate knowledge graphs from structured data or text found on the web is vital to addressing this demand. Current solutions to generating knowledge graphs include: SPARQL-Generate \cite{sparqlgenerate}, RML \cite{rml} and ChatGPT \cite{chatgptwebsite}. However, these tools are limited by their scope and complexity to reach the solution, so selecting SPARQL-Anything \cite{sparqlanythinggithub} for implementation was most favourable. 

Generating knowledge graphs directly from datasets is not trivial as the process is complex and requires understanding of knowledge engineering. Knowledge engineering requires experience and research in areas such as what ontologies to use or create, what vocabularies to use and what classes to use. So the process of generating knowledge graphs from a dataset is not instantaneous and requires research. In the case of smaller knowledge graphs, it is possible to manually create knowledge graphs without the use of a tool. Nevertheless, physically building the knowledge graph triple by triple would take a lot of time and is prone to human error for larger knowledge graphs and datasets. 

The project is part of the Polifonia project, which seeks to create an ecosystem of computational tools and methodologies to spread knowledge about musical history on the internet \cite{polifoniaproject}. This designated project involved a dataset centred around organs so the report includes a breakdown of the various organ components as well as background information regarding technical knowledge. 

This project will detail the process of knowledge graph generation using an organ-orientated dataset and provided ontology, both of which were contextualised to fully understand the dataset and to refine the existing ontology. In order to start the project, knowledge of the semantic web and it's capabilities was required so as to understand the scope of the project. Researching and being able to interpret RDF, ontologies and knowledge graphs is required to reach the solution as well as interpret it. 

The following chapters provide a comprehensive view of the design and implementation process for generating knowledge graphs. The design chapter complements the implementation phase by using visual tools and careful planning. Subsequently, the implementation chapter meticulously explains the steps required to reach the final solution. A thorough evaluation of the produced knowledge graph is performed with both qualitative and quantitative forms of assessment being carried out. The legal, social, ethical and professional issues surrounding this project are also reviewed to adhere to the Code of Conduct \& Code of Good Practice issued by the British Computer Society \cite{bcs}.

Finally, the conclusion will summarise the work completed during the course of this project and include a discussion on future work and limitations of the project.  

